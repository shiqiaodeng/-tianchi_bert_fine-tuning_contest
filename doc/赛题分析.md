## 赛题背景

本赛题由学术赛改编而来。部分问题可参考原赛题[论坛](https://tianchi.aliyun.com/competition/entrance/531841/forum)

自从2017年具有划时代意义的Transformer模型问世以来，短短两年多的时间内，如雨后春笋般的出现了大量的预训练模型，比如：Bert，Albert，ELECTRA，RoBERta，T5，GPT3等等。然而之前的基准评测体系存在两个缺陷：评测强度不够，模型不通用。评测强度不够指的是选手只提交结果，不提交inference的代码。模型不通用指的是预训练模型不能保证在相同超参数情况下在所有任务上都获得比较好的性能。以上两点极大限制了预训练技术的应用和发展。如果我们能通过算法实现泛化能力强的中文预训练模型，这将提高下游业务的准确性，从而提升企业的核心竞争力，并为企业创造更多的价值。

为提供更好的比赛体验，我们同时为本赛题定制了系列工具教程，其中包括EasyTransfer、多任务baseline教程等。同时我们也将提供专属的视频直播学习通道，具体关注本赛题「参考资料」版块。

## 赛题描述及数据说明

本赛题精选了以下3个具有代表性的任务，要求选手提交的模型能够同时预测每个任务对应的标签：

**数据说明**

**OCNLI**：是第一个非翻译的、使用原生汉语的大型中文自然语言推理数据集；
**OCEMOTION**：是包含7个分类的细粒度情感性分析数据集；
**TNEWS**：来源于今日头条的新闻版块，共包含15个类别的新闻；

**数据格式**

- 任务1：OCNLI--中文原版自然语言推理

```
0 一月份跟二月份肯定有一个月份有. 肯定有一个月份有 0  
1 一月份跟二月份肯定有一个月份有. 一月份有 1  
2 一月份跟二月份肯定有一个月份有. 一月二月都没有 2  
3 一点来钟时,张永红却来了 一点多钟,张永红来了 0  
4 不讲社会效果,信口开河,对任何事情都随意发议论,甚至信谣传谣,以讹传讹,那是会涣散队伍、贻误事业的 以讹传讹是有害的 0  
（注：id 句子1 句子2 标签）
```

（注：标签集合：[蕴含，中性，不相关]）

- 任务2：OCEMOTION--中文情感分类

```
0 你知道多伦多附近有什么吗?哈哈有破布耶...真的书上写的你听哦...你家那块破布是世界上最大的破布,哈哈,骗你的啦它是说尼加拉瓜瀑布是世界上最大的瀑布啦...哈哈哈''爸爸,她的头发耶!我们大扫除椅子都要翻上来我看到木头缝里有头发...一定是xx以前夹到的,你说是不是?[生病] sadness  
1 平安夜,圣诞节,都过了,我很难过,和妈妈吵了两天,以死相逼才终止战争,现在还处于冷战中。sadness  
2 我只是自私了一点,做自己想做的事情! sadness  
3 让感动的不仅仅是雨过天晴,还有泪水流下来的迷人眼神。happiness  
4 好日子 happiness  
```

（注：id 句子 标签）

- 任务3：TNEWS--今日头条新闻标题分类

```
0 上课时学生手机响个不停,老师一怒之下把手机摔了,家长拿发票让老师赔,大家怎么看待这种事? 108  
1 商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告 104  
2 通过中介公司买了二手房,首付都付了,现在卖家不想卖了。怎么处理? 106  
3 2018年去俄罗斯看世界杯得花多少钱? 112  
4 剃须刀的个性革新,雷明登天猫定制版新品首发 109  
```

（注：id 句子 标签）

## 评测方案

参赛选手仅可使用单模型，先求出每个任务的macro f1，然后在三个任务上取平均值，具体计算公式如下：

**计算公式：**

|        名称        |             说明             |
| :----------------: | :--------------------------: |
| TP(True Positive)  | 真阳性：预测为正，实际也为正 |
| FP(False Positive) |  假阳性：预测为正，实际为负  |
| FN(False Negative) |  假阴性：预测与负、实际为正  |
| TN(True Negative)  | 真阴性：预测为负、实际也为负 |
|    P(Precision)    |    精确率 P = TP/(TP+FP)     |
|     R(Recall)      |    召回率 R = TP/(TP+FN)     |
|    F(f1-score)     |      F-值 F = 2PR/(P+R)      |

**macro f1**
需要先计算出每一个类别的准召及其f1 score，然后通过求均值得到在整个样本上的f1 score。

sklearn 计算方式 (python):

```python
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report, f1_score

l_t, l_p = [1, 2, 3, 2, 3], [2, 2, 3, 2, 1]
marco_f1_score = f1_score(l_t, l_p, average='macro')
print(marco_f1_score)
print(f"{'confusion_matrix':*^80}")
print(confusion_matrix(l_t, l_p, ))
print(f"{'classification_report':*^80}")
print(classification_report(l_t, l_p, ))
```

示例输出：

```plain
0.48888888888888893
********************************confusion_matrix********************************
[[0 1 0]
 [0 2 0]
 [1 0 1]]
*****************************classification_report******************************
              precision    recall  f1-score   support

           1       0.00      0.00      0.00         1
           2       0.67      1.00      0.80         2
           3       1.00      0.50      0.67         2

    accuracy                           0.60         5
   macro avg       0.56      0.50      0.49         5
weighted avg       0.67      0.60      0.59         5
0.48888888888888893
********************************confusion_matrix********************************
[[0 1 0]
[0 2 0]
[1 0 1]]
*****************************classification_report******************************
          precision    recall  f1-score   support

       1       0.00      0.00      0.00         1
       2       0.67      1.00      0.80         2
       3       1.00      0.50      0.67         2

accuracy          					0.60   	5
macro avg       	0.56   	0.50  	0.49 	5
weighted avg       	0.67   	0.60  	0.59   	5
```

最终得分：
取每个任务的macro f1，最后取平均值，作为 最终得分。
计：

- macro_f1_ocnli 为ocnli任务的 macro_f1
- macro_f1_ocemotion 为ocemotion任务的 macro_f1
- macro_f1_tnews 为tnews任务的 macro_f1
  最终得分为：

```
score = (macro_f1_ocnli + macro_f1_ocemotion + macro_f1_tnews) / 3
```

## 提交说明

每个任务提交一个json文件（utf8编码，每一行为json格式数据，需包含id，顺序排列，命名规范为 **"任务名称+_predict.json"**格式）
如：

```plain
ocnli_predict.json
tnews_predict.json
ocemotion_predict.json
```

最后将这些文件压缩，命名为 **submit.zip** 压缩格式文件

## 比赛规则

- **学习赛测评使用初赛testB**
- 本次挑战可以使用公开数据资源（如使用开源数据或者代码模型，需要在最终提交文件中说明外部公开的资源，并在提交审核的代码文档中打包提供）；
- 禁止任何形式人工标注；
- 禁止仅使用开源的模型和代码，没有算法贡献的情况出现；
- 本次比赛只能使用单模型（**单模型的定义**：一个任务只能有一个预测函数，所有任务只能使用同一个bert，在计算图中只能有一个bert）完成任务，不能集成多个模型进行预测；
- 本次比赛的最终代码需要能够在天池实验室（PAI-DSW探索版）中运行，实验室配置详见“[使用天池实验室打比赛](https://tianchi.aliyun.com/competition/entrance/531841/notebook)"，每次进入最多使用8小时，不限次数。
- **模型调优阶段( finetune)只能使用比赛提供的数据**，预训练阶段可要使用外部数据（代码提交时在readme中说明来源）

## 数据集引用说明

- Hu, Hai, Kyle Richardson, Liang Xu, Lu Li, Sandra Kuebler, and Larry Moss. (2020). OCNLI: Original Chinese Natural Language Inference. In: Findings of the Association for Computational Linguistics: EMNLP 2020. pp. 3512-3526.
  论文链接是：https://www.aclweb.org/anthology/2020.findings-emnlp.314/
  (对应OCNLI)
- Minglei Li, Yunfei Long, Qin Lu, and Wenjie Li. “Emotion Corpus Construction Based on Selection from Hashtags.” In Proceedings of International Conference on Language Resources and Evaluation (LREC). Portorož, Slovenia, 2016
  论文链接: https://www.aclweb.org/anthology/L16-1291.pdf
  (对应情感分析数据集）